{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc1b062-1923-4258-ab8c-a8cc60c80024",
   "metadata": {},
   "source": [
    "# ðŸŒŒ Photo-Z Challenge: Training Pipeline\n",
    "\n",
    "Welcome to the Photo-Z Challenge! ðŸš€ This notebook provides a step-by-step guide to run the machine learning pipeline to predict redshift. \n",
    "\n",
    "We will learn from a baseline dataset representing nominal observational conditions. The training set is composed of 300,000 galaxies and 20,000 QSOs (Quasars).\n",
    "\n",
    "Let's start by setting up our environment ðŸ› ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6425e385-537a-4a8b-beb9-82072b1cd3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/hl4s187n5b37619mh7d94nb40000gn/T/ipykernel_85192/1086959399.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# --- 2. LIBRARIES ---\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95919037-6833-4652-9a23-7e6362225c5f",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 1: Configuration Definition\n",
    "\n",
    "We define the entire experiment configuration here. This dictionary contains the feature selection, model hyperparameters, and training settings.\n",
    "\n",
    "For example, the Artificial Neural Network (ANN) uses two hidden layers with 64 neurons each and dropout rates of 0.1.\n",
    "\n",
    "A key step is choosing which variables the ML models will use for training, such as magnitudes, J-PAS narrow-band photometry, or a combination of both. J-PAS fluxes are normalized to the **iSDSS** band by construction. Magnitudes, however, are **not** normalized and will only be normalized if they are included in `features_to_normalize`.\n",
    "\n",
    "Note that not all observations are available for every object. Missing measurements are represented as `np.nan` values. In this configuration, observational errors are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3559b394-2364-4115-b338-d4b9b7de90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment and model configuration embedded directly in the notebook\n",
    "cfg = {\n",
    "    \"experiment\": {\n",
    "        \"group_name\": \"Forest-Z\",\n",
    "        \"save_dir\": \"models/\"\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"train_path\": \"data/training_set.h5\", # Adjusted path assuming notebook is in photoz_challenge/\n",
    "        \"val_path\": \"data/validation_set.h5\",\n",
    "        \"batch_size\": 1000,\n",
    "        \"target_col\": \"Z\",\n",
    "        \"inputs\": {\n",
    "            \"FilterJPAS\": [\n",
    "                'J0378', 'J0390', 'J0400', 'J0410', 'J0420', 'J0430', 'J0440', 'J0450',\n",
    "                'J0460', 'J0470', 'J0480', 'J0490', 'J0500', 'J0510', 'J0520', 'J0530',\n",
    "                'J0540', 'J0550', 'J0560', 'J0570', 'J0580', 'J0590', 'J0600', 'J0610',\n",
    "                'J0620', 'J0630', 'J0640', 'J0650', 'J0660', 'J0670', 'J0680', 'J0690',\n",
    "                'J0700', 'J0710', 'J0720', 'J0730', 'J0740', 'J0750', 'J0760', 'J0770',\n",
    "                'J0780', 'J0790', 'J0800', 'J0810', 'J0820', 'J0830', 'J0840', 'J0850',\n",
    "                'J0860', 'J0870', 'J0880', 'J0890', 'J0900', 'J0910'\n",
    "            ],\n",
    "            \"MAGNITUDES\": [\n",
    "                'MAG_NUV','MAG_FUV','MAG_G','MAG_R','MAG_i','MAG_Z',\"MAG_J_2MASS\",\n",
    "                \"MAG_H_2MASS\",\"MAG_Ks_2MASS\",'MAG_W1','MAG_W2','MAG_W3','MAG_W4', 'iSDSS'\n",
    "            ]\n",
    "        },\n",
    "        \"selected_features\": [\"FilterJPAS\", \"MAGNITUDES\"],\n",
    "        \"features_to_normalize\": [\"MAGNITUDES\"]\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"type\": \"random_forest\", # Options: \"neural_net\", \"random_forest\"\n",
    "        \"hidden_layers\": [512, 512],\n",
    "        \"dropout_rates\": [0.2, 0.2],\n",
    "        \"output_size\": 1,\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 100\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss_type\": \"deltaz\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e10ad0-ff37-4b18-8b9c-5d0ed212625d",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 2: Model Architectures\n",
    "\n",
    "Here we define the machine learning algorithms used in the pipeline. By default, the workflow includes two models: an Artificial Neural Network (ANN) and a Random Forest (RF).\n",
    "\n",
    "We also define a custom `DeltaZLoss` function designed to optimize the standard photometric redshift (Photo-$z$) metric, defined as:\n",
    "\n",
    "$$\n",
    "\\Delta z = \\frac{\\left| z_{\\mathrm{pred}} - z_{\\mathrm{true}} \\right|}{1 + z_{\\mathrm{true}}}\n",
    "$$\n",
    "\n",
    "where $z_{\\mathrm{pred}}$ is the predicted redshift and $z_{\\mathrm{true}}$ is the spectroscopic (true) redshift.\n",
    "\n",
    "You are encouraged to experiment with alternative loss functions depending on the scientific objective or optimization strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e88ff0fd-1802-4cee-98c3-0cfff3f04c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhotoZNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, dropout_rates):\n",
    "        super(PhotoZNet, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        in_dim = input_size\n",
    "        \n",
    "        # Dynamic construction of hidden layers\n",
    "        for h_dim, drop_rate in zip(hidden_layers, dropout_rates):\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(drop_rate))\n",
    "            in_dim = h_dim\n",
    "            \n",
    "        # Linear output layer\n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DeltaZLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeltaZLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Standard Photo-Z metric: |dz| / (1+z)\n",
    "        numerator = torch.abs(y_pred - y_true)\n",
    "        denominator = 1.0 + y_true\n",
    "        return torch.mean(numerator / denominator)\n",
    "\n",
    "class RandomForestPhotoZ:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y.ravel())\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calculate predictions from all individual trees to estimate uncertainty\n",
    "        preds = np.array([tree.predict(X) for tree in self.model.estimators_])\n",
    "        mean_pred = np.mean(preds, axis=0)\n",
    "        std_pred = np.std(preds, axis=0) \n",
    "        return mean_pred, std_pred\n",
    "\n",
    "    def save(self, path):\n",
    "        joblib.dump(self.model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2d663-7217-4390-8c09-40715eaaf369",
   "metadata": {},
   "source": [
    "## ðŸ—‚ï¸ Step 3: Data Processing\n",
    "\n",
    "Data is the fuel for our models! Here we define our `Dataset` class and the `preprocess_data` function.\n",
    "\n",
    "This function handles missing values by replacing NaNs with `0.0` and applies normalization using the Median Absolute Deviation (MAD). The median and MAD are computed **only on the training set** to prevent data leakage into the validation set.\n",
    "\n",
    "You may also explore alternative strategies for handling missing data and different normalization approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92e96ede-95b9-447e-a91c-f3afb7927eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhotoZDataset(Dataset):\n",
    "    def __init__(self, features, targets, types):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets).reshape(-1, 1)\n",
    "        self.types = np.array(types)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx], self.types[idx]\n",
    "\n",
    "def get_mad(series):\n",
    "    median = series.median()\n",
    "    return (series - median).abs().median()\n",
    "\n",
    "def preprocess_data(df, config, train_stats=None):\n",
    "    selected_cols = []\n",
    "    for group in config['data']['selected_features']:\n",
    "        selected_cols.extend(config['data']['inputs'][group])\n",
    "    \n",
    "    X = df[selected_cols].copy()\n",
    "    y = df['Z'].values\n",
    "    types = df['TYPE'].values\n",
    "\n",
    "    # Replace NaN values with 0.0\n",
    "    X = X.fillna(0.0)\n",
    "\n",
    "    # Identify columns that need normalization\n",
    "    cols_to_norm = []\n",
    "    for group in config['data']['features_to_normalize']:\n",
    "        if group in config['data']['selected_features']:\n",
    "             cols_to_norm.extend(config['data']['inputs'][group])\n",
    "    \n",
    "    # Compute median and MAD only for the training set to prevent data leakage\n",
    "    if train_stats is None:\n",
    "        medians = X[cols_to_norm].median()\n",
    "        mads = X[cols_to_norm].apply(get_mad)\n",
    "        # Prevent division by zero\n",
    "        mads = mads.replace(0, 1.0)\n",
    "        train_stats = {'medians': medians, 'mads': mads}\n",
    "    \n",
    "    # Apply normalization using the training statistics\n",
    "    X[cols_to_norm] = (X[cols_to_norm] - train_stats['medians']) / train_stats['mads']\n",
    "    \n",
    "    return X.values, y, types, train_stats, len(selected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a3147-d9bc-4582-8c3a-9d4ebe789651",
   "metadata": {},
   "source": [
    "## ðŸ‹ï¸â€â™‚ï¸ Step 4: Training Pipeline Execution\n",
    "\n",
    "Time to train! ðŸ”¥ The `run_training` function orchestrates the whole process:\n",
    "1. Loads the `.h5` files into Pandas DataFrames.\n",
    "2. Preprocesses the data.\n",
    "3. Initializes the chosen model (Neural Network or Random Forest) based on `config.yaml`.\n",
    "4. Trains the model and evaluates it dynamically on validation GALAXY and QSO types.\n",
    "\n",
    "Note: if you choose the RF, the code below uses only **10%** of the data for speed. You may want to disable this subsampling to train on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3486488-95a5-4255-a7d2-edb5702d3c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Initializing Random Forest model 'Forest-Z'...\n",
      "Training Random Forest...\n",
      "Evaluating Random Forest on validation set...\n",
      "Val Loss Global: 0.0752 | GALAXY: 0.0552 | QSO: 0.1954\n",
      "\n",
      "Model saved to: models/Forest-Z_rf.joblib\n"
     ]
    }
   ],
   "source": [
    "def run_training(cfg):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    df_train = pd.read_hdf(cfg['data']['train_path'], key='data')\n",
    "    df_val = pd.read_hdf(cfg['data']['val_path'], key='data')\n",
    "\n",
    "    print(\"Preprocessing data...\")\n",
    "    X_train, y_train, types_train, stats, input_dim = preprocess_data(df_train, cfg, train_stats=None)\n",
    "    X_val, y_val, types_val, _, _ = preprocess_data(df_val, cfg, train_stats=stats)\n",
    "\n",
    "    model_type = cfg['model'].get('type', 'neural_net')\n",
    "    os.makedirs(cfg['experiment']['save_dir'], exist_ok=True)\n",
    "    \n",
    "    history = {'train': [], 'val_global': []}\n",
    "\n",
    "    if model_type == 'neural_net':\n",
    "        train_dataset = PhotoZDataset(X_train, y_train, types_train)\n",
    "        val_dataset = PhotoZDataset(X_val, y_val, types_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=cfg['data']['batch_size'], shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=cfg['data']['batch_size'], shuffle=False)\n",
    "        \n",
    "        print(f\"Initializing model '{cfg['experiment']['group_name']}'...\")\n",
    "        model = PhotoZNet(\n",
    "            input_size=input_dim,\n",
    "            hidden_layers=cfg['model']['hidden_layers'],\n",
    "            dropout_rates=cfg['model']['dropout_rates']\n",
    "        ).to(device)\n",
    "\n",
    "        criterion = DeltaZLoss() if cfg['training']['loss_type'] == 'deltaz' else nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg['training']['learning_rate'])\n",
    "\n",
    "        epochs = cfg['training']['epochs']\n",
    "        print(f\"Starting training for {epochs} epochs.\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss_acc = 0.0\n",
    "            \n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "            for inputs, targets, _ in pbar:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss_acc += loss.item()\n",
    "                pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "            \n",
    "            avg_train_loss = train_loss_acc / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss_acc = 0.0\n",
    "            all_val_outputs, all_val_targets, all_val_types = [], [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for v_inputs, v_targets, v_types in val_loader:\n",
    "                    v_inputs, v_targets = v_inputs.to(device), v_targets.to(device)\n",
    "                    v_outputs = model(v_inputs)\n",
    "                    v_loss = criterion(v_outputs, v_targets)\n",
    "                    \n",
    "                    val_loss_acc += v_loss.item()\n",
    "                    all_val_outputs.append(v_outputs.cpu())\n",
    "                    all_val_targets.append(v_targets.cpu())\n",
    "                    all_val_types.extend(v_types)\n",
    "                \n",
    "                total_val_loss = val_loss_acc / len(val_loader)\n",
    "                val_outputs_cat = torch.cat(all_val_outputs)\n",
    "                val_targets_cat = torch.cat(all_val_targets)\n",
    "                val_types_np = np.array(all_val_types)\n",
    "                \n",
    "                unique_types = np.unique(val_types_np)\n",
    "                type_metrics = {}\n",
    "                for t in unique_types:\n",
    "                    mask = (val_types_np == t)\n",
    "                    if np.sum(mask) > 0:\n",
    "                        type_metrics[t] = criterion(val_outputs_cat[mask], val_targets_cat[mask]).item()\n",
    "\n",
    "            msg = f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f} | Val Loss Global: {total_val_loss:.4f}\"\n",
    "            for t, l in type_metrics.items():\n",
    "                msg += f\" | {t}: {l:.4f}\"\n",
    "            print(msg)\n",
    "\n",
    "            history['train'].append(avg_train_loss)\n",
    "            history['val_global'].append(total_val_loss)\n",
    "            for t, l in type_metrics.items():\n",
    "                k = f\"val_{t}\"\n",
    "                if k not in history:\n",
    "                    history[k] = []\n",
    "                history[k].append(l)\n",
    "\n",
    "        save_path = os.path.join(cfg['experiment']['save_dir'], f\"{cfg['experiment']['group_name']}.pth\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"\\nModel saved to: {save_path}\")\n",
    "\n",
    "    elif model_type == 'random_forest':\n",
    "        # Sample 10% of the training data for speed (you may want to disable this)\n",
    "        n_sample = max(1, int(0.1 * X_train.shape[0]))\n",
    "        sample_indices = np.random.choice(X_train.shape[0], size=n_sample, replace=False)\n",
    "        X_train, y_train, types_train = X_train[sample_indices], y_train[sample_indices], types_train[sample_indices]\n",
    "\n",
    "        print(f\"Initializing Random Forest model '{cfg['experiment']['group_name']}'...\")\n",
    "        rf_model = RandomForestPhotoZ(\n",
    "            n_estimators=cfg['model'].get('n_estimators', 100),\n",
    "            max_depth=cfg['model'].get('max_depth', None)\n",
    "        )\n",
    "        \n",
    "        print(\"Training Random Forest...\")\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"Evaluating Random Forest on validation set...\")\n",
    "        mean_pred, std_pred = rf_model.predict(X_val)\n",
    "        \n",
    "        y_val_flat = y_val.ravel()\n",
    "        numerator = np.abs(mean_pred - y_val_flat)\n",
    "        denominator = 1.0 + y_val_flat\n",
    "        total_val_loss = np.mean(numerator / denominator)\n",
    "        \n",
    "        unique_types = np.unique(types_val)\n",
    "        type_metrics = {}\n",
    "        for t in unique_types:\n",
    "            mask = (types_val == t)\n",
    "            if np.sum(mask) > 0:\n",
    "                type_metrics[t] = np.mean(\n",
    "                    np.abs(mean_pred[mask] - y_val_flat[mask]) / (1.0 + y_val_flat[mask])\n",
    "                )\n",
    "        \n",
    "        msg = f\"Val Loss Global: {total_val_loss:.4f}\"\n",
    "        for t, l in type_metrics.items():\n",
    "            msg += f\" | {t}: {l:.4f}\"\n",
    "        print(msg)\n",
    "        \n",
    "        history['val_global'].append(total_val_loss)\n",
    "        for t, l in type_metrics.items():\n",
    "            k = f\"val_{t}\"\n",
    "            if k not in history:\n",
    "                history[k] = []\n",
    "            history[k].append(l)\n",
    "\n",
    "        save_path = os.path.join(cfg['experiment']['save_dir'], f\"{cfg['experiment']['group_name']}_rf.joblib\")\n",
    "        rf_model.save(save_path)\n",
    "        print(f\"\\nModel saved to: {save_path}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "history = run_training(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d7d6e-df07-4a8d-91e2-810468bcd8c4",
   "metadata": {},
   "source": [
    "## ðŸ“‰ Step 5: Learning Curves Visualization\n",
    "\n",
    "In order to understand how our Neural Network is learning, we need to look at the **Loss vs. Epoch** plot! \n",
    "\n",
    "This plot will help us diagnose if our model is **underfitting** (high loss on both train and validation), **overfitting** (train loss goes down, but validation loss goes up), or training perfectly! We break down the validation loss into the global metric, and the specific metrics for **Galaxies** and **QSOs**  to see if the model struggles with a particular type of object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80d87f5b-6f57-4422-bb97-07ec092a70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning curves only available for ANN algorithm\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation losses as a function of epoch.\n",
    "\n",
    "    Expected 'history' dictionary format:\n",
    "    {\n",
    "        'train': [loss_ep1, loss_ep2, ...],\n",
    "        'val_global': [loss_ep1, loss_ep2, ...],\n",
    "        'val_GALAXY': [loss_ep1, loss_ep2, ...],\n",
    "        'val_QSO': [loss_ep1, loss_ep2, ...]\n",
    "    }\n",
    "\n",
    "    The loss corresponds to the standard photometric redshift metric:\n",
    "\n",
    "        Î”z = |z_pred âˆ’ z_true| / (1 + z_true)\n",
    "\n",
    "    where:\n",
    "        z_pred : predicted redshift\n",
    "        z_true : spectroscopic (true) redshift\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the number of epochs from the training history length\n",
    "    epochs = range(1, len(history['train']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot main loss curves with thicker lines\n",
    "    plt.plot(epochs, history['train'],\n",
    "             label='Train Loss', linewidth=3, color='cyan')\n",
    "\n",
    "    plt.plot(epochs, history['val_global'],\n",
    "             label='Val Loss (Global)', linewidth=3, color='magenta')\n",
    "\n",
    "    # Plot class-specific validation losses if available\n",
    "    if 'val_GALAXY' in history and len(history['val_GALAXY']) > 0:\n",
    "        plt.plot(epochs, history['val_GALAXY'],\n",
    "                 label='Val Loss (GALAXY)',\n",
    "                 linewidth=3, linestyle='--', color='yellow')\n",
    "\n",
    "    if 'val_QSO' in history and len(history['val_QSO']) > 0:\n",
    "        plt.plot(epochs, history['val_QSO'],\n",
    "                 label='Val Loss (QSO)',\n",
    "                 linewidth=3, linestyle='-.', color='lime')\n",
    "\n",
    "    # Axis labels\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.ylabel(r'Loss ($\\Delta z$)', fontsize=16)\n",
    "\n",
    "    # Larger tick labels\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # Disable grid for cleaner dark-background visualization\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Legend formatting\n",
    "    plt.legend(loc='upper right', fontsize=14)\n",
    "\n",
    "    plt.title('Learning Curves', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "try :\n",
    "    plot_learning_curves(history)\n",
    "except :\n",
    "    print('Learning curves only available for ANN algorithm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62710fc6-33ec-45c9-a916-ba089ea51ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
